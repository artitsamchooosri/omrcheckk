{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet152V2\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = 'omr.v6i.folder/train/'\n",
    "test_dir = 'omr.v6i.folder/test/'\n",
    "val_dir = 'omr.v6i.folder/valid/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = image_dataset_from_directory(train_dir,labels='inferred',\n",
    "                                       label_mode='categorical',interpolation='nearest',image_size=[150,150],batch_size=32,\n",
    "                                       shuffle=True)\n",
    "data_validation = image_dataset_from_directory(val_dir,labels='inferred',\n",
    "                                       label_mode='categorical',interpolation='nearest',image_size=[150,150],batch_size=32,\n",
    "                                       shuffle=True)\n",
    "data_test = image_dataset_from_directory(test_dir,labels='inferred',\n",
    "                                       label_mode='categorical',interpolation='nearest',image_size=[150,150],batch_size=32,\n",
    "                                       shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_train = data_train.class_names\n",
    "classes_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = (256, 256)\n",
    "\n",
    "# data argumentation\n",
    "train_datagen = ImageDataGenerator(rescale=1/255.0,\n",
    "                                       rotation_range=45,\n",
    "                                       shear_range=0.2,\n",
    "                                       zoom_range=0.2,\n",
    "                                       horizontal_flip=True,\n",
    "                                       vertical_flip=True\n",
    "                                       )\n",
    "\n",
    "# data argumentation\n",
    "test_datagen = ImageDataGenerator(rescale= 1 / 255.0)\n",
    "\n",
    "train_dataset = train_datagen.flow_from_directory(train_dir, target_size=(IMG_SIZE), \n",
    "                                         color_mode=\"rgb\",\n",
    "                                         batch_size=16, \n",
    "                                         shuffle=True,\n",
    "                                         class_mode=\"categorical\")\n",
    "\n",
    "test_dataset = test_datagen.flow_from_directory(test_dir, target_size=(IMG_SIZE), \n",
    "                                         color_mode=\"rgb\",\n",
    "                                         batch_size=16, \n",
    "                                         shuffle=True,\n",
    "                                         class_mode=\"categorical\")\n",
    "\n",
    "validation_dataset = train_datagen.flow_from_directory(val_dir, target_size=(IMG_SIZE), \n",
    "                                         color_mode=\"rgb\",\n",
    "                                         batch_size=16, \n",
    "                                         shuffle=True,\n",
    "                                         class_mode=\"categorical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# using resnet152v2 model\n",
    "resnet152v2 = ResNet152V2(weights='imagenet',include_top=False,input_shape=(256,256,3))\n",
    "# make pre trained model into non trainable bcoz its takes much time\n",
    "for layer in resnet152v2.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model in sequential\n",
    "model = Sequential()\n",
    "# add resnet101v2 model into our sequence model\n",
    "model.add(resnet152v2)\n",
    "# flatten the model\n",
    "model.add(Flatten())\n",
    "# Adding dense layers\n",
    "model.add(Dense(128, activation=\"relu\", kernel_initializer=\"he_uniform\"))\n",
    "# Adding output layer\n",
    "model.add(Dense(5,activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compile\n",
    "model.compile(optimizer=Adam(),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    validation_data=validation_dataset,\n",
    "                    epochs=1,\n",
    "                    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocessing(path):\n",
    "    sample_mask_img = cv2.imread(path)\n",
    "    sample_mask_img = cv2.resize(sample_mask_img,(256,256))\n",
    "    plt.imshow(sample_mask_img)\n",
    "    sample_mask_img = np.reshape(sample_mask_img,[1,256,256,3])\n",
    "    sample_mask_img = sample_mask_img/255.0\n",
    "    return sample_mask_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = img_preprocessing('omr.v6i.folder/test/4/th5115-jpg_8_jpg.rf.a6624367b8b247e200d663823f4b4b66.jpg')\n",
    "np.argmax(model.predict(img1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('yologpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab77c09c13a1deedf3a14bb2aae5fad66c8ae92cafd0515ce37fb52678a97a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
