{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "729312d2-05d8-47fb-a9b5-817d4b4375e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.layers import Input, Flatten, Dense, Dropout,GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfab0cf-5867-4833-adf2-b2ff88a3a568",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_working_dir = os.getcwd()\n",
    "root_dir=old_working_dir+'\\\\omr.v6i.folder'\n",
    "TRAIN_SAMPLES = 100\n",
    "VALIDATION_SAMPLES=100\n",
    "TRAIN_DATA_DIR = root_dir+'\\\\train'\n",
    "VALIDATION_DATA_DIR = root_dir + '\\\\test'\n",
    "NUM_CLASSES = 5\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.3)\n",
    "val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "                        TRAIN_DATA_DIR,\n",
    "                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=True,\n",
    "                        seed=12345,\n",
    "                        class_mode='categorical')\n",
    "\n",
    "validation_generator = val_datagen.flow_from_directory(\n",
    "                        VALIDATION_DATA_DIR,\n",
    "                        target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        shuffle=False,\n",
    "                        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c8cbb9-92f1-4ac4-9bf9-9b17597fc3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_maker():\n",
    "    base_model = MobileNet(include_top=False, input_shape = (IMG_WIDTH,IMG_HEIGHT,3))\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False # Freeze the layers\n",
    "        \n",
    "    input = Input(shape=(IMG_WIDTH, IMG_HEIGHT, 3))\n",
    "    custom_model = base_model(input)\n",
    "    custom_model = GlobalAveragePooling2D()(custom_model)\n",
    "    custom_model = Dense(64, activation='relu')(custom_model)\n",
    "    custom_model = Dropout(0.5)(custom_model)\n",
    "    predictions  = Dense(NUM_CLASSES, activation='softmax')(custom_model)\n",
    "    \n",
    "    return Model(inputs=input, outputs=predictions)\n",
    "def prepare(filepath):\n",
    "    IMG_SIZE = 224 \n",
    "    img_array = cv2.imread(filepath)\n",
    "    new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "    return new_array.reshape(-1, IMG_SIZE, IMG_SIZE, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75db567-dd60-4fec-930e-ba43ef1289fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model_maker()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer= tf.keras.optimizers.Adam(lr=0.001),\n",
    "              metrics=['acc'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4b3b0b6-9ae9-43a4-87af-a21b00279945",
   "metadata": {},
   "outputs": [],
   "source": [
    "history=model.fit(train_generator, steps_per_epoch = math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE), epochs=50, validation_data = validation_generator, validation_steps = math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f452799e-b9f3-4247-b6ce-6ed7f84fe232",
   "metadata": {},
   "source": [
    "history=model.fit(train_generator, steps_per_epoch = math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE), epochs=50, validation_data = validation_generator, validation_steps = math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "a4863192-9f13-4882-87c3-d69bc0aca357",
   "metadata": {},
   "source": [
    "history=model.fit(train_generator,\n",
    "                    epochs=50,\n",
    "                    validation_data = validation_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5ed897-0bf3-481a-97d9-a2b12a062b59",
   "metadata": {},
   "source": [
    "history=model.fit(train_generator,\n",
    "                    steps_per_epoch = math.ceil(float(TRAIN_SAMPLES) / BATCH_SIZE),\n",
    "                    epochs=10,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = math.ceil(float(VALIDATION_SAMPLES) / BATCH_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cdd62b6-5e0b-4448-a760-44585b14e9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"fang2_mobilenet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a4e2a6b-abd7-4b71-bfc9-f92921c1ad0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a157bd-62dc-49f6-a9fd-bfa82d1d6af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['acc'], label='Accuracy')\n",
    "plt.plot(history.history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('CNN Metrices (Accuracy)')\n",
    "plt.ylabel('% value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d604bd7-8d0d-4611-b104-44d50559c746",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'], label='Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.title('CNN Metrices(Loss)')\n",
    "plt.ylabel('% value')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cabdba8-1acd-4dab-92c1-bc2e4955e0d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model,load_model\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "\n",
    "model = load_model('fang2_mobilenet.h5')\n",
    "def load(path):\n",
    "    image = tf.keras.preprocessing.image.load_img(path)\n",
    "    image = tf.image.resize(image, [224,224])\n",
    "    input_arr = tf.keras.preprocessing.image.img_to_array(image)\n",
    "    np_image = np.array(input_arr).astype('float32')/255\n",
    "    np_image = np.expand_dims(np_image, axis=0)\n",
    "    return np_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9aa458-dfb0-4ee6-8e14-0dbd2d0ac3cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'opencv_frame_1.png'\n",
    "np_images=load(path)\n",
    "prediction = model.predict(np_images)\n",
    "print(\"Predictions:\")\n",
    "print(prediction)\n",
    "print(np.argmax(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ea2fe7-e26d-47d9-ad7f-760e160ad00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79073792-367b-4cda-b968-7cd2cc7fef03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "if tf.test.gpu_device_name(): \n",
    "\n",
    "    print('Default GPU Device:\n",
    "\n",
    "    {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "else:\n",
    "\n",
    "   print(\"Please install GPU version of TF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12471bfe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('yologpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ab77c09c13a1deedf3a14bb2aae5fad66c8ae92cafd0515ce37fb52678a97a43"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
